{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading https://files.pythonhosted.org/packages/00/37/a392e669a83fef72b916009c438a924d2a9d70bc8aea62662b207105ed98/lightgbm-2.2.3-py2.py3-none-win_amd64.whl (515kB)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\rafael\\documents\\python\\current\\python-3.6.7.amd64\\lib\\site-packages (from lightgbm) (0.20)\n",
      "Requirement already satisfied: scipy in c:\\users\\rafael\\documents\\python\\current\\python-3.6.7.amd64\\lib\\site-packages (from lightgbm) (1.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\rafael\\documents\\python\\current\\python-3.6.7.amd64\\lib\\site-packages (from lightgbm) (1.14.6+mkl)\n",
      "Installing collected packages: lightgbm\n",
      "Successfully installed lightgbm-2.2.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/titanic_proc.csv\", index_col=\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pase_id;dias_navegacion_x;n_visitas_x;n_disp_x;v_pw_x;q_notas_x;q_homes_x;pv_deportes_x;pv_espectaculos_x;pv_estilo_x;pv_noticias_x;pv_servicios_x;pv_sudoku_x;pv_sociedad_x;a_edad;antiguedad_pase;q_visitas;genero_n;Segmento;susc_target\n",
      "\n",
      "214;4;1;1;0;3;4;0;0;0;0;0;0;15;30;2288;12;0;1;0\n",
      "\n",
      "337;5;1;1;0;3;829;0;2;0;7;0;0;2;53;2286;12;1;2;0\n",
      "\n",
      "345;3;1;1;0;3;1;0;3;0;1;0;0;2;64;2286;8;0;1;0\n",
      "\n",
      "364;9;1;1;6;26;919;143;4;0;63;0;4;54;40;2283;11;0;2;0\n",
      "\n",
      "368;8;1;1;1;20;16;0;45;8;20;0;0;49;19;2283;12;0;1;0\n",
      "\n",
      "388;1;1;1;0;0;0;1;0;0;0;0;0;0;71;2277;7;1;1;0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(r\"C:/Users/Rafael/Documents/data/clarin_clase_210906/paywall_v.csv\") as f:\n",
    "    for i, l in enumerate(f):\n",
    "        print(l)\n",
    "        if i > 5:\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r\"C:/Users/Rafael/Documents/data/clarin_clase_210906/paywall_v.csv\", index_col=\"pase_id\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in data.select_dtypes(\"object\").columns:\n",
    "    data[c] = data[c].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dias_navegacion_x    int64\n",
       "n_visitas_x          int64\n",
       "n_disp_x             int64\n",
       "v_pw_x               int64\n",
       "q_notas_x            int64\n",
       "q_homes_x            int64\n",
       "pv_deportes_x        int64\n",
       "pv_espectaculos_x    int64\n",
       "pv_estilo_x          int64\n",
       "pv_noticias_x        int64\n",
       "pv_servicios_x       int64\n",
       "pv_sudoku_x          int64\n",
       "pv_sociedad_x        int64\n",
       "a_edad               int64\n",
       "antiguedad_pase      int64\n",
       "q_visitas            int64\n",
       "genero_n             int64\n",
       "Segmento             int64\n",
       "susc_target          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"susc_target\"\n",
    "# target = \"Survived\"\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(data.drop(target, axis=1), \n",
    "                                                                    data[target], test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = model_selection.KFold(n_splits=5)\n",
    "folds = [(y_train.index[train_idx], \n",
    "          y_train.index[valid_idx]) for train_idx, valid_idx \n",
    "         in kf.split(X_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's auc: 0.730178\ttraining's binary_logloss: 0.0109918\tvalid_1's auc: 0.692216\tvalid_1's binary_logloss: 0.0105291\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's auc: 0.718161\ttraining's binary_logloss: 0.0103142\tvalid_1's auc: 0.698548\tvalid_1's binary_logloss: 0.00909039\n",
      "[3]\ttraining's auc: 0.737981\ttraining's binary_logloss: 0.010242\tvalid_1's auc: 0.705375\tvalid_1's binary_logloss: 0.00934371\n",
      "[4]\ttraining's auc: 0.745272\ttraining's binary_logloss: 0.0102647\tvalid_1's auc: 0.703256\tvalid_1's binary_logloss: 0.00966249\n",
      "[5]\ttraining's auc: 0.754321\ttraining's binary_logloss: 0.0100994\tvalid_1's auc: 0.706547\tvalid_1's binary_logloss: 0.00961131\n",
      "[6]\ttraining's auc: 0.759987\ttraining's binary_logloss: 0.010078\tvalid_1's auc: 0.703326\tvalid_1's binary_logloss: 0.00979764\n",
      "[7]\ttraining's auc: 0.765731\ttraining's binary_logloss: 0.0099601\tvalid_1's auc: 0.699018\tvalid_1's binary_logloss: 0.00984366\n",
      "[8]\ttraining's auc: 0.771271\ttraining's binary_logloss: 0.0100471\tvalid_1's auc: 0.693488\tvalid_1's binary_logloss: 0.0100522\n",
      "[9]\ttraining's auc: 0.77439\ttraining's binary_logloss: 0.00976912\tvalid_1's auc: 0.689641\tvalid_1's binary_logloss: 0.00984942\n",
      "[10]\ttraining's auc: 0.780038\ttraining's binary_logloss: 0.00973983\tvalid_1's auc: 0.684867\tvalid_1's binary_logloss: 0.00992708\n",
      "[11]\ttraining's auc: 0.784679\ttraining's binary_logloss: 0.00977041\tvalid_1's auc: 0.683874\tvalid_1's binary_logloss: 0.0101869\n",
      "[12]\ttraining's auc: 0.785907\ttraining's binary_logloss: 0.00955993\tvalid_1's auc: 0.677614\tvalid_1's binary_logloss: 0.010027\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.718161\ttraining's binary_logloss: 0.0103142\tvalid_1's auc: 0.698548\tvalid_1's binary_logloss: 0.00909039\n",
      "[1]\ttraining's auc: 0.722438\ttraining's binary_logloss: 0.0105456\tvalid_1's auc: 0.708066\tvalid_1's binary_logloss: 0.0105687\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's auc: 0.723847\ttraining's binary_logloss: 0.0101836\tvalid_1's auc: 0.707391\tvalid_1's binary_logloss: 0.00994761\n",
      "[3]\ttraining's auc: 0.730529\ttraining's binary_logloss: 0.0100649\tvalid_1's auc: 0.709247\tvalid_1's binary_logloss: 0.01003\n",
      "[4]\ttraining's auc: 0.733537\ttraining's binary_logloss: 0.00988325\tvalid_1's auc: 0.704929\tvalid_1's binary_logloss: 0.00998693\n",
      "[5]\ttraining's auc: 0.751491\ttraining's binary_logloss: 0.00983145\tvalid_1's auc: 0.720695\tvalid_1's binary_logloss: 0.00996658\n",
      "[6]\ttraining's auc: 0.768711\ttraining's binary_logloss: 0.0100032\tvalid_1's auc: 0.720642\tvalid_1's binary_logloss: 0.0104753\n",
      "[7]\ttraining's auc: 0.773803\ttraining's binary_logloss: 0.00993157\tvalid_1's auc: 0.725136\tvalid_1's binary_logloss: 0.0106631\n",
      "[8]\ttraining's auc: 0.778231\ttraining's binary_logloss: 0.00972973\tvalid_1's auc: 0.722659\tvalid_1's binary_logloss: 0.0103632\n",
      "[9]\ttraining's auc: 0.786358\ttraining's binary_logloss: 0.00973151\tvalid_1's auc: 0.719561\tvalid_1's binary_logloss: 0.0105845\n",
      "[10]\ttraining's auc: 0.79046\ttraining's binary_logloss: 0.0097718\tvalid_1's auc: 0.714257\tvalid_1's binary_logloss: 0.0107303\n",
      "[11]\ttraining's auc: 0.791574\ttraining's binary_logloss: 0.009548\tvalid_1's auc: 0.711092\tvalid_1's binary_logloss: 0.0105146\n",
      "[12]\ttraining's auc: 0.801446\ttraining's binary_logloss: 0.00950616\tvalid_1's auc: 0.70951\tvalid_1's binary_logloss: 0.0106193\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.723847\ttraining's binary_logloss: 0.0101836\tvalid_1's auc: 0.707391\tvalid_1's binary_logloss: 0.00994761\n",
      "[1]\ttraining's auc: 0.718289\ttraining's binary_logloss: 0.00987476\tvalid_1's auc: 0.706811\tvalid_1's binary_logloss: 0.0117011\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's auc: 0.721556\ttraining's binary_logloss: 0.00947786\tvalid_1's auc: 0.703807\tvalid_1's binary_logloss: 0.0111863\n",
      "[3]\ttraining's auc: 0.76559\ttraining's binary_logloss: 0.00951513\tvalid_1's auc: 0.736139\tvalid_1's binary_logloss: 0.0113243\n",
      "[4]\ttraining's auc: 0.766854\ttraining's binary_logloss: 0.00926097\tvalid_1's auc: 0.733891\tvalid_1's binary_logloss: 0.0111763\n",
      "[5]\ttraining's auc: 0.773981\ttraining's binary_logloss: 0.00914278\tvalid_1's auc: 0.727973\tvalid_1's binary_logloss: 0.0111581\n",
      "[6]\ttraining's auc: 0.783787\ttraining's binary_logloss: 0.0093659\tvalid_1's auc: 0.726179\tvalid_1's binary_logloss: 0.01161\n",
      "[7]\ttraining's auc: 0.785425\ttraining's binary_logloss: 0.0092398\tvalid_1's auc: 0.720252\tvalid_1's binary_logloss: 0.0116936\n",
      "[8]\ttraining's auc: 0.790054\ttraining's binary_logloss: 0.00900842\tvalid_1's auc: 0.715645\tvalid_1's binary_logloss: 0.0113981\n",
      "[9]\ttraining's auc: 0.792411\ttraining's binary_logloss: 0.00889543\tvalid_1's auc: 0.71342\tvalid_1's binary_logloss: 0.0113925\n",
      "[10]\ttraining's auc: 0.796804\ttraining's binary_logloss: 0.00885769\tvalid_1's auc: 0.711101\tvalid_1's binary_logloss: 0.0114661\n",
      "[11]\ttraining's auc: 0.801151\ttraining's binary_logloss: 0.00894261\tvalid_1's auc: 0.709584\tvalid_1's binary_logloss: 0.011624\n",
      "[12]\ttraining's auc: 0.801458\ttraining's binary_logloss: 0.00881435\tvalid_1's auc: 0.706652\tvalid_1's binary_logloss: 0.0115924\n",
      "[13]\ttraining's auc: 0.807816\ttraining's binary_logloss: 0.00935418\tvalid_1's auc: 0.705309\tvalid_1's binary_logloss: 0.0124375\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttraining's auc: 0.76559\ttraining's binary_logloss: 0.00951513\tvalid_1's auc: 0.736139\tvalid_1's binary_logloss: 0.0113243\n",
      "[1]\ttraining's auc: 0.703753\ttraining's binary_logloss: 0.010202\tvalid_1's auc: 0.621208\tvalid_1's binary_logloss: 0.0110826\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's auc: 0.704467\ttraining's binary_logloss: 0.00978036\tvalid_1's auc: 0.620487\tvalid_1's binary_logloss: 0.0108685\n",
      "[3]\ttraining's auc: 0.746796\ttraining's binary_logloss: 0.00989203\tvalid_1's auc: 0.664352\tvalid_1's binary_logloss: 0.0110914\n",
      "[4]\ttraining's auc: 0.743505\ttraining's binary_logloss: 0.00964295\tvalid_1's auc: 0.67185\tvalid_1's binary_logloss: 0.0108477\n",
      "[5]\ttraining's auc: 0.76723\ttraining's binary_logloss: 0.00961811\tvalid_1's auc: 0.690991\tvalid_1's binary_logloss: 0.0111713\n",
      "[6]\ttraining's auc: 0.770608\ttraining's binary_logloss: 0.00941218\tvalid_1's auc: 0.690898\tvalid_1's binary_logloss: 0.010958\n",
      "[7]\ttraining's auc: 0.779549\ttraining's binary_logloss: 0.00930074\tvalid_1's auc: 0.697745\tvalid_1's binary_logloss: 0.0110009\n",
      "[8]\ttraining's auc: 0.786555\ttraining's binary_logloss: 0.0093703\tvalid_1's auc: 0.700051\tvalid_1's binary_logloss: 0.011097\n",
      "[9]\ttraining's auc: 0.787172\ttraining's binary_logloss: 0.00931729\tvalid_1's auc: 0.701151\tvalid_1's binary_logloss: 0.0110873\n",
      "[10]\ttraining's auc: 0.792721\ttraining's binary_logloss: 0.00976106\tvalid_1's auc: 0.701627\tvalid_1's binary_logloss: 0.0118492\n",
      "[11]\ttraining's auc: 0.793772\ttraining's binary_logloss: 0.00942694\tvalid_1's auc: 0.700161\tvalid_1's binary_logloss: 0.011609\n",
      "[12]\ttraining's auc: 0.79475\ttraining's binary_logloss: 0.00925733\tvalid_1's auc: 0.700472\tvalid_1's binary_logloss: 0.0115681\n",
      "[13]\ttraining's auc: 0.799098\ttraining's binary_logloss: 0.00965908\tvalid_1's auc: 0.700626\tvalid_1's binary_logloss: 0.0117939\n",
      "[14]\ttraining's auc: 0.798032\ttraining's binary_logloss: 0.00937767\tvalid_1's auc: 0.699639\tvalid_1's binary_logloss: 0.0117504\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttraining's auc: 0.743505\ttraining's binary_logloss: 0.00964295\tvalid_1's auc: 0.67185\tvalid_1's binary_logloss: 0.0108477\n",
      "[1]\ttraining's auc: 0.701814\ttraining's binary_logloss: 0.0103404\tvalid_1's auc: 0.710422\tvalid_1's binary_logloss: 0.010847\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\ttraining's auc: 0.741153\ttraining's binary_logloss: 0.00990262\tvalid_1's auc: 0.716175\tvalid_1's binary_logloss: 0.0103384\n",
      "[3]\ttraining's auc: 0.74987\ttraining's binary_logloss: 0.00974977\tvalid_1's auc: 0.698586\tvalid_1's binary_logloss: 0.0102864\n",
      "[4]\ttraining's auc: 0.76502\ttraining's binary_logloss: 0.00961615\tvalid_1's auc: 0.707485\tvalid_1's binary_logloss: 0.0102808\n",
      "[5]\ttraining's auc: 0.766749\ttraining's binary_logloss: 0.00946541\tvalid_1's auc: 0.712803\tvalid_1's binary_logloss: 0.0101371\n",
      "[6]\ttraining's auc: 0.773419\ttraining's binary_logloss: 0.00941426\tvalid_1's auc: 0.710916\tvalid_1's binary_logloss: 0.0101332\n",
      "[7]\ttraining's auc: 0.781093\ttraining's binary_logloss: 0.00928769\tvalid_1's auc: 0.709698\tvalid_1's binary_logloss: 0.01015\n",
      "[8]\ttraining's auc: 0.790671\ttraining's binary_logloss: 0.00920647\tvalid_1's auc: 0.709243\tvalid_1's binary_logloss: 0.010212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9]\ttraining's auc: 0.797198\ttraining's binary_logloss: 0.0100248\tvalid_1's auc: 0.705502\tvalid_1's binary_logloss: 0.011651\n",
      "[10]\ttraining's auc: 0.799744\ttraining's binary_logloss: 0.00977853\tvalid_1's auc: 0.701303\tvalid_1's binary_logloss: 0.0116973\n",
      "[11]\ttraining's auc: 0.803393\ttraining's binary_logloss: 0.00946772\tvalid_1's auc: 0.696588\tvalid_1's binary_logloss: 0.0114534\n",
      "[12]\ttraining's auc: 0.80644\ttraining's binary_logloss: 0.00929928\tvalid_1's auc: 0.694052\tvalid_1's binary_logloss: 0.0113664\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttraining's auc: 0.741153\ttraining's binary_logloss: 0.00990262\tvalid_1's auc: 0.716175\tvalid_1's binary_logloss: 0.0103384\n"
     ]
    }
   ],
   "source": [
    "valid_probs = []\n",
    "test_probs = []\n",
    "for i, (train_idx, valid_idx) in enumerate(folds):\n",
    "    Xt = X_train.loc[train_idx]\n",
    "    yt = y_train.loc[train_idx]\n",
    "\n",
    "    Xv = X_train.loc[valid_idx]\n",
    "    yv = y_train.loc[valid_idx]\n",
    "\n",
    "    learner = LGBMClassifier(n_estimators=10000)\n",
    "    learner.fit(Xt, yt,  early_stopping_rounds=10, eval_metric=\"auc\",\n",
    "                eval_set=[(Xt, yt),\n",
    "                          (Xv, yv)])\n",
    "    probs = pd.Series(learner.predict_proba(Xv)[:, -1], index=Xv.index)\n",
    "    valid_probs.append(probs)\n",
    "    probs = pd.Series(learner.predict_proba(X_test)[:, -1],\n",
    "                      index=X_test.index, name=\"fold_\" + str(i))\n",
    "    test_probs.append(probs)\n",
    "valid_probs = pd.concat(valid_probs)\n",
    "test_probs = pd.concat(test_probs, axis=1).mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7362436957609646"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, test_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>susc_target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prob</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(-0.00017900000000000001, 0.00108]</th>\n",
       "      <td>18554</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00108, 0.00115]</th>\n",
       "      <td>14236</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00115, 0.00123]</th>\n",
       "      <td>15360</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00123, 0.00142]</th>\n",
       "      <td>15831</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(0.00142, 0.398]</th>\n",
       "      <td>15910</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "susc_target                             0   1\n",
       "prob                                         \n",
       "(-0.00017900000000000001, 0.00108]  18554   2\n",
       "(0.00108, 0.00115]                  14236   9\n",
       "(0.00115, 0.00123]                  15360  15\n",
       "(0.00123, 0.00142]                  15831  27\n",
       "(0.00142, 0.398]                    15910  49"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testeo = test_probs.rename(\"prob\").to_frame().join(data[target])\n",
    "pd.crosstab(pd.qcut(testeo.prob, 5), testeo[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_visitas_x           0\n",
       "pv_servicios_x        0\n",
       "genero_n              0\n",
       "Segmento              1\n",
       "q_visitas             1\n",
       "pv_sudoku_x           2\n",
       "pv_noticias_x         2\n",
       "dias_navegacion_x     2\n",
       "n_disp_x              2\n",
       "pv_deportes_x         3\n",
       "pv_espectaculos_x     3\n",
       "q_notas_x             4\n",
       "pv_sociedad_x         4\n",
       "pv_estilo_x           4\n",
       "v_pw_x                6\n",
       "a_edad                7\n",
       "antiguedad_pase       7\n",
       "q_homes_x            12\n",
       "dtype: int32"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(learner.feature_importances_, index=Xt.columns).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>susc_target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>q_homes_x</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999431</td>\n",
       "      <td>0.000569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999253</td>\n",
       "      <td>0.000747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999003</td>\n",
       "      <td>0.000997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999056</td>\n",
       "      <td>0.000944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998652</td>\n",
       "      <td>0.001348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998365</td>\n",
       "      <td>0.001635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.998982</td>\n",
       "      <td>0.001018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999300</td>\n",
       "      <td>0.000700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.998543</td>\n",
       "      <td>0.001457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.997784</td>\n",
       "      <td>0.002216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.998406</td>\n",
       "      <td>0.001594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.999034</td>\n",
       "      <td>0.000966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.998578</td>\n",
       "      <td>0.001422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.999042</td>\n",
       "      <td>0.000958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.998160</td>\n",
       "      <td>0.001840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.997874</td>\n",
       "      <td>0.002126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.998299</td>\n",
       "      <td>0.001701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.997869</td>\n",
       "      <td>0.002131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.998840</td>\n",
       "      <td>0.001160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.997746</td>\n",
       "      <td>0.002254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.998520</td>\n",
       "      <td>0.001480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.998473</td>\n",
       "      <td>0.001527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.999026</td>\n",
       "      <td>0.000974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.998356</td>\n",
       "      <td>0.001644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.998534</td>\n",
       "      <td>0.001466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.998711</td>\n",
       "      <td>0.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.997998</td>\n",
       "      <td>0.002002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.996871</td>\n",
       "      <td>0.003129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.998638</td>\n",
       "      <td>0.001362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.998785</td>\n",
       "      <td>0.001215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1767</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1768</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1769</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1773</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1776</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1778</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1783</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1785</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1787</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1789</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1791</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1797</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1798</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1805</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1702 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "susc_target         0         1\n",
       "q_homes_x                      \n",
       "0            0.999431  0.000569\n",
       "1            0.999253  0.000747\n",
       "2            0.999003  0.000997\n",
       "3            0.999056  0.000944\n",
       "4            0.998652  0.001348\n",
       "5            0.998365  0.001635\n",
       "6            0.998982  0.001018\n",
       "7            0.999300  0.000700\n",
       "8            0.998543  0.001457\n",
       "9            0.997784  0.002216\n",
       "10           0.998406  0.001594\n",
       "11           0.999034  0.000966\n",
       "12           0.998578  0.001422\n",
       "13           0.999042  0.000958\n",
       "14           0.998160  0.001840\n",
       "15           0.997874  0.002126\n",
       "16           0.998299  0.001701\n",
       "17           0.997869  0.002131\n",
       "18           0.998840  0.001160\n",
       "19           0.997746  0.002254\n",
       "20           0.998520  0.001480\n",
       "21           0.998473  0.001527\n",
       "22           0.999026  0.000974\n",
       "23           0.998356  0.001644\n",
       "24           0.998534  0.001466\n",
       "25           0.998711  0.001289\n",
       "26           0.997998  0.002002\n",
       "27           0.996871  0.003129\n",
       "28           0.998638  0.001362\n",
       "29           0.998785  0.001215\n",
       "...               ...       ...\n",
       "1766         1.000000  0.000000\n",
       "1767         1.000000  0.000000\n",
       "1768         1.000000  0.000000\n",
       "1769         1.000000  0.000000\n",
       "1770         1.000000  0.000000\n",
       "1773         1.000000  0.000000\n",
       "1776         1.000000  0.000000\n",
       "1778         1.000000  0.000000\n",
       "1779         1.000000  0.000000\n",
       "1780         1.000000  0.000000\n",
       "1781         1.000000  0.000000\n",
       "1782         1.000000  0.000000\n",
       "1783         1.000000  0.000000\n",
       "1785         1.000000  0.000000\n",
       "1786         1.000000  0.000000\n",
       "1787         1.000000  0.000000\n",
       "1788         1.000000  0.000000\n",
       "1789         1.000000  0.000000\n",
       "1791         1.000000  0.000000\n",
       "1792         1.000000  0.000000\n",
       "1793         1.000000  0.000000\n",
       "1794         1.000000  0.000000\n",
       "1796         1.000000  0.000000\n",
       "1797         1.000000  0.000000\n",
       "1798         1.000000  0.000000\n",
       "1800         1.000000  0.000000\n",
       "1801         1.000000  0.000000\n",
       "1804         1.000000  0.000000\n",
       "1805         1.000000  0.000000\n",
       "1808         1.000000  0.000000\n",
       "\n",
       "[1702 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(data.q_homes_x, data[target]).apply(lambda x: x / x.sum(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
